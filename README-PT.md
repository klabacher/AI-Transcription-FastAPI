# ğŸš€ API de TranscriÃ§Ã£o Otimizada

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klabacher/your-repo-name/blob/main/V3_Colab_Demo.ipynb)
[![Feito com FastAPI](https://img.shields.io/badge/Feito%20com-FastAPI-blue.svg)](https://fastapi.tiangolo.com/)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/release/python-3100/)
[![LicenÃ§a: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[Read in English](./README.md)

Uma API de transcriÃ§Ã£o de Ã¡udio de alta performance, construÃ­da com FastAPI e focada em oferecer acesso a modelos de *state-of-the-art* como `faster-whisper` e versÃµes otimizadas do Hugging Face.

O projeto foi desenhado para ser robusto e eficiente, utilizando workers em processos isolados para lidar com o processamento pesado de IA, garantindo que a API principal permaneÃ§a sempre responsiva.

*(Um GIF demonstrando a interface web seria Ã³timo aqui!)*

## âœ¨ Features Principais

- **Workers Persistentes**: Modelos de IA sÃ£o carregados uma Ãºnica vez em processos worker separados, eliminando o tempo de carregamento a cada requisiÃ§Ã£o e otimizando o uso de recursos (CPU/GPU).
- **Sistema de Fila de Jobs**: As tarefas de transcriÃ§Ã£o sÃ£o enfileiradas e processadas de forma assÃ­ncrona, permitindo que a API lide com um grande volume de requisiÃ§Ãµes.
- **DetecÃ§Ã£o de Hardware**: A API detecta automaticamente a presenÃ§a de uma GPU (CUDA) e suas capacidades (como suporte a FP16) para ativar os modelos mais performÃ¡ticos.
- **Setup Automatizado**: Na primeira execuÃ§Ã£o, um script de setup baixa e armazena em cache todos os modelos de IA necessÃ¡rios, agilizando as inicializaÃ§Ãµes futuras.
- **Interface de Testes (UI)**: Uma interface web simples e funcional (`/ui`) para testar a API, enviar arquivos, acompanhar o progresso dos jobs e visualizar os resultados.
- **Processamento de MÃºltiplos Arquivos e .ZIP**: Envie vÃ¡rios arquivos de Ã¡udio ou um Ãºnico arquivo `.zip` contendo os Ã¡udios para criar mÃºltiplos jobs de uma sÃ³ vez.
- **Monitoramento e Gerenciamento**: Endpoints para verificar o status de jobs especÃ­ficos, cancelar tarefas em andamento e limpar jobs antigos automaticamente.

## ğŸ› ï¸ Stack e Escolhas de Arquitetura

- **FastAPI**: Para APIs de alta performance e documentaÃ§Ã£o automÃ¡tica.
- **Multiprocessing**: Para isolar os workers de IA do processo principal da API, garantindo a responsividade.
- **Vanilla JS/HTML/CSS**: Para uma UI leve, funcional e fÃ¡cil de entender.
- **IA e Ãudio**: `faster-whisper`, `transformers`, `torch`, e `soundfile`.

## ğŸ§  Modelos DisponÃ­veis

| Model ID | ImplementaÃ§Ã£o | Requer GPU? | DescriÃ§Ã£o |
| :--- | :--- | :--- | :--- |
| `distil_large_v3_ptbr` | Hugging Face | â– NÃ£o | Recomendado para testes locais. Ã“tima qualidade em PT-BR, leve e rÃ¡pido em CPU. |
| `faster_medium_fp16` | faster-whisper | âœ… Sim | Excelente equilÃ­brio entre velocidade e qualidade em GPU. |
| `faster_large_v3_fp16` | faster-whisper | âœ… Sim | MÃ¡xima qualidade e precisÃ£o em PT-BR. Requer GPU potente (VRAM > 8GB). |
| `faster_large-v3_int8` | faster-whisper | â– NÃ£o | Qualidade do Large-v3 com menor uso de memÃ³ria. Ideal para CPUs potentes ou GPUs com VRAM limitada. |

## ğŸš€ Como Usar

VocÃª pode executar este projeto usando Docker (recomendado) ou configurando um ambiente Python local.

### PrÃ©-requisitos
- Python 3.10+
- Docker e Docker Compose (para a configuraÃ§Ã£o com containers).
- (Opcional) GPU NVIDIA com drivers CUDA para a melhor performance.

### ğŸ³ OpÃ§Ã£o 1: Executando com Docker (Recomendado)
1.  **Clone o repositÃ³rio:**
    ```bash
    git clone https://github.com/klabacher/your-repo-name.git # Substitua pela URL do seu repositÃ³rio
    cd your-repo-name
    ```
2.  **Construa e execute:**
    ```bash
    docker-compose up --build
    ```
    > **Nota:** O primeiro lanÃ§amento levarÃ¡ vÃ¡rios minutos para baixar os modelos de IA.

3.  **Acesse a aplicaÃ§Ã£o:**
    - **UI Web**: `http://127.0.0.1:8000/ui`
    - **Docs da API**: `http://127.0.0.1:8000/docs`

### ğŸ OpÃ§Ã£o 2: Ambiente Python Local
1.  **Clone, crie um ambiente virtual e ative-o.**
2.  **Instale as dependÃªncias:** `pip install -r requirements.txt`
3.  **Inicie a API:** `uvicorn main:app --reload`
4.  **Acesse a aplicaÃ§Ã£o** nas mesmas URLs listadas acima.

## â˜ï¸ Uso na Nuvem (Google Colab)

Para usuÃ¡rios que desejam testar a API sem uma configuraÃ§Ã£o local, um notebook do Google Colab Ã© fornecido (`V3_Colab_Demo.ipynb`). Ele permite que vocÃª execute a aplicaÃ§Ã£o completa na infraestrutura de nuvem do Google gratuitamente.

**Como usar:**

1.  **Abra no Google Colab:**
    *   Clique no selo "Open in Colab" no topo deste README ou abra manualmente o `V3_Colab_Demo.ipynb` no [Google Colab](https://colab.research.google.com/) atravÃ©s da aba GitHub.

2.  **Selecione um Ambiente com GPU (Recomendado):**
    *   No Colab, vÃ¡ em `Ambiente de execuÃ§Ã£o` -> `Alterar o tipo de ambiente de execuÃ§Ã£o` e selecione `T4 GPU`.

3.  **Execute as CÃ©lulas:**
    *   Execute as cÃ©lulas do notebook em ordem. O notebook irÃ¡ guiÃ¡-lo na instalaÃ§Ã£o de dependÃªncias, inicializaÃ§Ã£o da API e envio de um job de teste.

## ğŸ“¡ Endpoints da API

- `GET /`: Status da API e informaÃ§Ãµes de hardware.
- `GET /models`: Lista os modelos disponÃ­veis.
- `GET /queues`: Monitora as filas de jobs.
- `POST /jobs`: Cria jobs de transcriÃ§Ã£o.
- `GET /jobs/{job_id}`: Verifica o status do job.
- `POST /jobs/{job_id}/cancel`: Cancela um job.
- `GET /jobs/{job_id}/download`: Baixa o resultado da transcriÃ§Ã£o.

## ğŸ“„ LicenÃ§a

Este projeto foi criado por **[klabacher](https://github.com/klabacher)** e estÃ¡ licenciado sob a **LicenÃ§a MIT**. Pedimos que, por favor, forneÃ§a atribuiÃ§Ã£o ao usar este cÃ³digo.

## â¤ï¸ CrÃ©ditos e Agradecimentos

- **Criador**:
    - **[klabacher](https://github.com/klabacher)**: Desenvolvimento inicial e arquitetura do projeto.
- **Modelos de IA**:
    - Agradecimentos a **OpenAI**, **Guillaume Klein (SYSTRAN)**, e **freds0** no Hugging Face.
- **Ferramentas**:
    - [FastAPI](https://fastapi.tiangolo.com/), [PyTorch](https://pytorch.org/), e [Hugging Face](https://huggingface.co/).

---

> **Aviso**: Este projeto foi desenvolvido com o auxÃ­lio de InteligÃªncia Artificial.
