# üöÄ API de Transcri√ß√£o H√≠brida (FaaS-like)

Uma API de transcri√ß√£o de √°udio robusta, local e ass√≠ncrona, constru√≠da em Python com FastAPI. O sistema foi projetado para ser "Function as a Service"-like, permitindo o processamento de √°udios em background, monitoramento de filas e gerenciamento autom√°tico de cache, com uma interface web simples para testes e uso pr√°tico.

> ‚ÑπÔ∏è **Nota de Colabora√ß√£o com IA**
> Este projeto foi desenvolvido em uma colabora√ß√£o interativa entre um desenvolvedor humano e a intelig√™ncia artificial **Gemini**, do Google. A IA foi utilizada como uma parceira de programa√ß√£o para arquitetar a solu√ß√£o, refatorar c√≥digo, gerar implementa√ß√µes e documentar as funcionalidades.

> ‚ö†Ô∏è **Atribui√ß√£o e Propriedade dos Modelos**
> Este projeto √© uma **ferramenta de orquestra√ß√£o** e n√£o reivindica a propriedade de nenhum dos modelos de machine learning que utiliza. Todo o cr√©dito pertence aos seus respectivos criadores e mantenedores:
> * **Whisper:** Desenvolvido e liberado pela [OpenAI](https://openai.com/research/whisper).
> * **Faster-Whisper:** Uma reimplementa√ß√£o otimizada criada por [Guillaume Luga](https://github.com/guillaumekln/faster-whisper).
> * **Distil-Whisper:** Modelos destilados e otimizados, disponibilizados pela [Hugging Face](https://huggingface.co/distil-whisper) e pela comunidade (ex: [freds0](https://huggingface.co/freds0/distil-whisper-large-v3-ptbr)).
> * **AssemblyAI:** Uma plataforma comercial de Speech-to-Text via API, propriedade da [AssemblyAI, Inc](https://www.assemblyai.com/).

---

## ‚ú® Features Principais

* **Motor H√≠brido:** Suporte nativo para m√∫ltiplos backends:
    * **Modelos Locais:** Rode transcri√ß√µes na sua pr√≥pria m√°quina (CPU ou GPU).
    * **Nuvem:** Integre com servi√ßos de ponta como o **AssemblyAI**.
* **Sele√ß√£o Inteligente de Dispositivo:** Detec√ß√£o autom√°tica de GPU (CUDA) para m√°xima performance, com a op√ß√£o de for√ßar o uso de CPU (`AUTOMATICO`/`GPU`/`CPU`).
* **Processamento Ass√≠ncrono:** Envie um ou v√°rios √°udios (inclusive `.zip`) e receba um `job_id` imediatamente. A API processa tudo em background, sem travar.
* **Interface Web (HUD):** Um painel de controle simples e funcional em `/ui` para testar todas as funcionalidades da API sem precisar de c√≥digo.
* **Monitoramento de Filas:** Um endpoint (`/queues`) que permite visualizar todos os jobs em andamento, sua porcentagem e tempo estimado de conclus√£o (ETA), com filtros por usu√°rio.
* **Sistema de Sess√µes Descentralizado:** Agrupe jobs por usu√°rio ou cliente atrav√©s de uma `session_id` an√¥nima, sem necessidade de login ou banco de dados.
* **Limpeza Autom√°tica de Cache (Janitor):** Um "faxineiro" roda em background para apagar resultados de jobs antigos, mantendo a mem√≥ria da API eficiente.
* **Downloads de Resultados:** Baixe as transcri√ß√µes em m√∫ltiplos formatos: `.txt` individuais, um arquivo √∫nico concatenado ou um pacote `.zip` completo.
* **Setup Autom√°tico:** Na inicializa√ß√£o, a API verifica e baixa automaticamente os modelos locais necess√°rios.

## üõ†Ô∏è Tecnologias Utilizadas

* **Backend:** Python 3.10+
* **Framework API:** FastAPI
* **Servidor ASGI:** Uvicorn
* **Machine Learning & √Åudio:**
    * PyTorch
    * OpenAI-Whisper
    * Faster-Whisper
    * Transformers (Hugging Face)
* **APIs Externas:** AssemblyAI
* **Interface (HUD):** HTML5, CSS3, JavaScript (Vanilla)

---

## üöÄ Come√ßando

Siga os passos abaixo para ter a API rodando na sua m√°quina.

### 1. Pr√©-requisitos

* Python 3.10 ou superior.
* `git` para clonar o reposit√≥rio.
* (Opcional, mas recomendado para performance) Uma GPU NVIDIA com CUDA instalado para processamento com os modelos locais.

### 2. Instala√ß√£o

Clone o reposit√≥rio para a sua m√°quina local:
```bash
git clone <URL_DO_SEU_REPOSITORIO_GIT>
cd transcription_api
```

Crie e ative um ambiente virtual (recomendado):
```bash
# Criar o ambiente
python -m venv venv

# Ativar no Linux/macOS
source venv/bin/activate

# Ativar no Windows (PowerShell)
.\venv\Scripts\Activate.ps1
```

Instale todas as depend√™ncias do projeto:
```bash
pip install -r requirements.txt
```
*Nota: A primeira instala√ß√£o pode demorar, pois baixa bibliotecas pesadas como o PyTorch.*

### 3. Configura√ß√£o

As configura√ß√µes principais podem ser ajustadas no arquivo `config.py`:
* `JOB_RETENTION_TIME_SECONDS`: Tempo (em segundos) que um job finalizado fica na mem√≥ria antes de ser limpo. (Padr√£o: 3600s = 1 hora)
* `JANITOR_SLEEP_INTERVAL_SECONDS`: Frequ√™ncia (em segundos) com que o processo de limpeza roda. (Padr√£o: 300s = 5 minutos)

---

## ‚ñ∂Ô∏è Executando a API

Com o ambiente virtual ativado, inicie o servidor com Uvicorn:

```bash
uvicorn main:app --reload
```
Para debug:
```bash
DEBUG=true uvicorn main:app --reload
```
* O comando `--reload` reinicia o servidor automaticamente sempre que voc√™ salvar uma altera√ß√£o no c√≥digo.

Na primeira vez que voc√™ iniciar, a API vai **baixar e configurar todos os modelos locais**. Isso pode levar v√°rios minutos e consumir alguns gigabytes de espa√ßo em disco. Nas inicializa√ß√µes seguintes, o processo ser√° quase instant√¢neo.

Quando o servidor estiver pronto, voc√™ ver√° uma mensagem como:
`INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)`

## üïπÔ∏è Como Usar

A aplica√ß√£o oferece tr√™s pontos de acesso principais:

### 1. Interface de Usu√°rio (HUD)
A maneira mais f√°cil de usar e testar.
* **Acesse:** [**http://127.0.0.1:8000/ui**](http://127.0.0.1:8000/ui)
* A HUD permite selecionar o motor, o modelo, enviar arquivos (inclusive `.zip`), configurar op√ß√µes e ver os resultados e downloads em tempo real.

### 2. Documenta√ß√£o da API (Swagger UI)
Para desenvolvedores que querem interagir diretamente com os endpoints.
* **Acesse:** [**http://127.0.0.1:8000/docs**](http://127.0.0.1:8000/docs)
* Voc√™ pode testar cada endpoint, ver os par√¢metros necess√°rios e os modelos de resposta.

### 3. Monitoramento de Filas
Para ver o status de todos os jobs no sistema.
* **Acesse:** [**http://127.0.0.1:8000/queues**](http://127.0.0.1:8000/queues)
* Para filtrar por usu√°rios espec√≠ficos, adicione os `session_id` na URL:
    `http://127.0.0.1:8000/queues?session_ids=ID_SESSAO_1,ID_SESSAO_2`

---

## üèõÔ∏è Arquitetura da Solu√ß√£o

* **API com FastAPI:** Escolhido pela alta performance, tipagem de dados com Pydantic e gera√ß√£o autom√°tica de documenta√ß√£o.
* **Jobs em Background:** Para tarefas de longa dura√ß√£o como a transcri√ß√£o, a API usa `BackgroundTasks` para liberar o cliente imediatamente, evitando timeouts.
* **Gerenciamento de Estado em Mem√≥ria:** O estado dos jobs e as filas s√£o mantidos em um dicion√°rio Python. Esta √© uma solu√ß√£o simples e eficaz para uma aplica√ß√£o local e de inst√¢ncia √∫nica.
* **Janitor com Threading:** Um processo de limpeza √© disparado em uma thread separada durante o ciclo de vida da aplica√ß√£o (`lifespan`) para n√£o bloquear o servidor principal.

## üìú Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.